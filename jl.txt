期望工作内容：爬虫+langchain+自然语言处理相关工程开发岗。使用LangChain基于llama3-70B构建求职助手，借助Puppeteer实现自动回复HR问题。在文本分类任务上，基于HuggingFace微调DistilBERT模型，封装为Docker镜像，对外提供API。可维护改写已有PyTorch/TensorFlow代码。可从头编写、维护、改写C/C++代码。能够快速融入新的工作环境并推动项目的顺利进行。
工作经历与精选项目
自己的项目 LANGCHAIN APP设计 2024年5月至今 （注：工作经历往下翻）
LangChain APP设计/LangChain、Prompt、QA、爬虫、Streamlit、NodeJS、Puppeteer、SDXL、llama3、PyQT
•	求职助手 APP
•	Node.JS端。
	第一部分：定时扫描会话，自动回复。
	扫描HR最后的n句，送模型回复。Finish
	黑表中的公司，回复固定内容。Finish
	检测我回复内容中含有“再见”、“不合适”，入黑表。
	第二部分：自动招呼。finish
	黑表过滤。投递表过滤。职位名称过滤。职位地址过滤。距离过滤。风险过滤。
	使用 Puppeteer 获取公司信息，包括名称、状态和风险内容，并根据自身风险（最大值50，权重0.5）、关联风险（最大值50，权重0.4）和提示信息（最大值100，权重0.1）的加权综合得分评估公司的综合风险水平。如果公司状态为 "非开业"，直接将风险值设定为1。finish
	通勤距离计算。通过 Puppeteer 自动化浏览器获取两个地名的经纬度，并返回一个包含这两个地名的经纬度及其之间直线距离（以公里为单位）的字典。finish
	风险、距离入投递表。
	第三部分：数据库。
	黑表。公司名。Finish
	投递表。
•	LangChain服务端
•	https://baiziyuandyufei-langchain-ap-job-search-assistant-server-ykvejz.streamlit.app/
该项目旨在开发一个基于 Langchain和 llama-v3-70b-instruct  模型的对话机器人，主要用于替我同 HR  对话。项目涉及多项前沿技术。它的功能就是钉钉个人版/AI助理/指令中心/面试官的反向功能，在我的APP中，你的角色是面试官，AI的角色是求职者，代替我回答你的问题，当然这个APP是针对我个人的特点进行定制回答的，它不仅能回答业务问题，特别地也能根据我的简历内容以及对应聘企业的要求回答相关问题。
 	 
左图为钉钉的面试官，右图为我的求职助手，这里我让它钉钉问问题，让我的APP回答问题。
1. 问题分类链设计
针对特定问题给出特定的提示，输入语言模型生成回答。在求职助手项目中，我设计并实现了问题分类链。具体实现包括使用少样本提示（Few-Shot Prompt）生成初始输入，通过聊天模型处理并生成分类结果，接着利用字符串输出解析器（StrOutputParser）解析模型输出，最后通过RunnableLambda函数将分类标签转换为具体的响应。这一设计有效提高了系统对用户问题的分类和理解能力，为后续处理提供了准确的上下文信息。
2. 问题检索链设计
针对问题检索简历中相关内容作为提示，输入语言模型生成回答。在求职助手项目中，我设计并实现了问题检索链。具体实现包括使用检索器（retriever）获取相关文档，并通过RunnableLambda函数将文档内容提取并合并为统一文本。该设计确保了系统能够高效地从知识库中检索出与用户问题相关的信息，从而为生成准确的回答提供了可靠的依据。
3. 基于LCEL融合分类链与检索链
在求职助手项目中，我采用LangChain Execution Language (LCEL)的方法，将问题分类链和问题检索链融合。具体实现包括使用RunnablePassthrough传递用户问题，并通过RunnableParallel并行调用分类链和检索链，然后利用RunnableLambda生成上下文提示，接着通过ChatPromptTemplate整合系统和用户消息，最终调用聊天模型生成响应并解析输出。该方法提高了系统的智能化和响应准确度，使求职助手能够更好地回答用户的问题。
4. APP 在线服务
在求职助手项目中，我开发了一个基于Streamlit的APP服务，实现了与HR互动的智能聊天机器人。该应用使用FireWorks的llama-v3-70b-instruct模型，通过简洁的人机交互界面，用户可以方便地输入问题并收到智能回复。项目功能包括初始化聊天会话、显示聊天记录和自动回复。此外，还计划通过puppeteer实现BOSS直聘上的自动回复，并开发职位匹配和距离计算工具。
中科院信工所（非外协）2018年8月至2024年5月 
自然语言处理工程师/BERT、Transformers、PyTorch、BiLSTM-CRF、Scrapy
•	工作内容
独自负责舆情分析中自然语言处理相关内容。主要工作内容为社交短文本分类，完成数据获取、语料清洗、模型构建和部署等任务。在实际项目中创新性地应用技术和工具来解决问题的能力，简要概括：
- 自动化数据收集：利用大模型（如预训练的语言模型）自动抓取网页新闻的标题和内容，这不仅提高了数据收集的效率，还可能获取到更广泛、最新的数据资源。
- 基于NB模型的关键词提取：通过Naive Bayes分类器来识别和提取类别关键词，这一方法能够有效地提纯和聚焦训练语料，确保模型学习到更具代表性的特征。
- MaxEnt模型的实体识别优化：利用最大熵模型为实体识别结果打分，这是一种增强模型输出确定性的策略，有助于提升实体识别的准确率和鲁棒性。
- 大模型生成训练数据：通过大模型自动生成文本分类的训练语料，这是数据增强的一种高级形式，尤其适用于数据稀缺的场景，能够大幅丰富训练数据的多样性和覆盖范围。
•	社交短文本分类项目
1. 数据的获取
- 爬取 sougou  词库词典，解码转为普通可读文本文件。作用为为后续基于词典预测文本类别。制作链接爬虫，记录链接地址和链接名称，构建链接库。作用为根据用户提供的类别名称快速检索到对应的文本语料。制作语料爬虫。 提供两种爬虫形式。形式一：基于 scrapy  爬取链接库中的所有链接对应的语料，实现定期更新语料库。形式二：单链接爬虫。只爬取一个链接对应的全部语料。
- 交互界面设计与制作。基于flask+jquery+bootstrap+ajax  制作链接库管理界面和爬虫界面。功能包括：增删改查链接，爬取按钮，爬取过程日志的显示，类目体系显示，类目数据量分布显示，类目下文本显示。
2. 基于朴素贝叶斯模型净化训练语料
- 商品标题领域和新闻标题领域选择贝努力还是多项式分类模型？本系统使用多项式。
汉语分词与训练速度的关系。并没有使用去停用词或保留关键词，因为社交文本用词丰富，没有词表可囊括。只用词长和词形去掉没有意义的词语。
- 进一步优化了训练数据，根据混淆矩阵分布均匀的列去除了一个类目，分布均匀的行去除了一个类目，以确保数据的平衡性。同时，我根据训练好的模型，找出了每个类别的关键词，作为该类别的代表特征，用于净化训练语料。此外，我也过滤了数据量小于400的类目，以提高模型的泛化能力和分类效果。这些优化措施有助于提高模型对各类别的识别准确度和分类性能。
- 获取各类别关键词。基于训练好的模型，找出每个类别的关键词。模型训练好后，找出各类别得分最高的词语，就是该类别的关键词，传统模型的优势就在这里。使用类别关键词净化训练语料。
3. 基于 distilbert base multilingual cased  模型构建文本分类模型
- 为什么要用 distilbert ？使用 DistilmBERT  模型的原因是它在与朴素贝叶斯模型相比具有更好的性能和效率。首先，DistilmBERT  是一个经过蒸馏的模型，相比于朴素贝叶斯模型，它能够捕捉更复杂的语言结构和语义信息，从而提高了分类任务的准确性。其次，DistilmBERT  在处理多语言文本时也表现出色，因为它是在包含104种不同语言的维基百科数据上训练的，具有更好的泛化能力。与 bert base chinese  相比，DistilmBERT  的优势在于其更小的模型尺寸和更高的运行速度。虽然 BERT base chinese  是专门为处理中文文本而设计的，但它的模型参数更多，运行速度较慢。相比之下，DistilmBERT  在保持相近性能的情况下，模型更为轻量化，速度更快，适用于需要快速推理的场景。
使用新闻内容长文本微调大模型。
- 微调模型的步骤及注意点。（1）分词以及编码：此部分主要完成分词，填充，截断，掩码的生成。注意 cpu  内存受限时，需要对训练集分批次处理。（2）实现自定义 Dataset类，transformer  训练类只接受该类型的数据。重写初始化方法，获取元素方法，统计长度方法。使用编码后的数据集初始化该类的实例，后续实例化训练类。（3）定义模型评价方法。计算模型准确率和召回率。（4）设置训练超参数。周期数应该设置多少？三周期内不收敛说明代码中存在问题。批次大小主要取决于 GPU  内存。较大的批次，模型收敛快，但可能会陷入局部最优解，出现过拟合。较小的批次，提高模型泛化能力，可以让模型学习到不同样本之间的差异。学习率设置应当适中。过大，损失值不断增加，模型不收敛。过小，收敛速度较慢。（5）保持模型和分词编码器。如果想保存完整模型，需要将模型和分词器同时保存起来，便于以后加载自己微调后的模型，而无需再加载预训练的语言模型。
4. 模型预测
支持单条和批量预测，满足用户要求。
长文本的预测。语种识别，汉英分词与关键词抽取。受模型对输入文本长度的限制，也是为了确保模型预测准确性，对于所有输入文本，加入预处理步骤，执行语种识别，分词和关键词抽取，将抽取出的关键词送入模型进行预测。
5. 上线部署
Fastapi+uvicorn  封装为 docker  镜像，locust  负载测试。I7cpu 32g ram ，每秒请求数33，平均响应时间275ms。
6. 评测
- GPU配置：Tesla T4 GPU，15G内存。
- 数据比例：Number of Classes: 31 Train Size: 54660 Val Size: 13665 Test Size: 17082
- 数据比例净化后：Number of Classes: 16 Train Size: 18684 Val Size: 4672 Test Size: 5839
- 微调日志净化后： [3504/3504 51:08, Epoch 3/3]
Step Training Loss Validation Loss Accuracy F1
500	1.135300	0.313274	0.953125	0.952321
3500	0.078400	0.107589	0.977740	0.977640
- 分类报告：
accuracy 0.74 17082
macro avg 0.34 0.39 0.36 17082
weighted avg 0.65 0.74 0.69 17082
-分类报告净化后：
accuracy   0.95 5839
macro avg 0.94  0.92  0.93  5839
weighted avg 0.95  0.95  0.95  5839	

苏宁易购  2017年7月至2018年8月
自然语言处理工程师/朴素贝叶斯、C/C++、NLTK
•	工作内容
我负责了一个千万级商品分类项目，采用了C++多线程技术和朴素贝叶斯模型，旨在提高处理效率和分类准确性，以增强用户搜索体验。同时，我利用NLTK工具包进行商品标题近义词挖掘，丰富了搜索引擎关键词库，提高了搜索结果的准确性和用户体验。通过预处理、分词和构建词共现矩阵，实现了近义词抽取，捕捉了词语的语义关联和相似度。我的工作成果包括每周评测和持续监测商品分类模型的准确率和召回率，确保其维持在90%以上，提高了分类的准确性和稳定性。通过参数调优和算法改进，我不断优化了模型性能，及时响应用户反馈，提升了系统稳定性和可靠性。利用近义词挖掘技术丰富了搜索引擎关键词库，改进了系统功能和性能，提高了搜索结果准确性和用户体验。
•	商品标题分类项目
该项目是一个商品标题分类项目，利用了C++多线程技术和朴素贝叶斯模型。它包括了数据预处理模块、训练模块和预测模块，通过统计词到类目的映射来实现商品标题的分类。每周组织产品工程师进行模型效果评测，给出每周模型的准确率和召回率，并随时维护线上服务，快速进行人工干预以防止badcase的出现。
同方知网  2015年3月至2017年7月
自然语言处理工程师/计算语言学、C/C++、MySQL、MaxEnt、openCV
•	工作内容
我在同方知网完成了论文抄袭检测任务，采用了C++编程语言。我设计了基于标点符号的特征抽取方法，通过哈希映射将特征存储到MySQL数据库中，实现了有效的论文抄袭检测。这些工作有助于维护学术界的诚信，有效杜绝了学术造假的现象，保障了科研的可信度和学术的真实性。
•	”的地得“语法纠错项目
我负责了一个名为“的地得”语法纠错项目。该项目采用了最大熵模型，旨在识别和纠正文本中“的地得”用法错误。首先，我们搜集了大量的文本数据，并进行了预处理，包括分词、词性标注等。然后，我们设计了特征抽取方法，将文本中的“的地得”用法错误作为目标，提取了与其相关的上下文信息、词性信息等特征。接下来，我们使用最大熵模型进行训练，以学习正确的“的地得”用法，并对文本中的错误进行识别和纠正。最后，我们对模型进行评估和调优，确保其在实际应用中具有较高的准确性和可靠性。通过这个项目，我们能够有效提高文本的语法准确性，提升用户阅读体验。
技能
Python、C++、CRF、MaxEnt、LSTM、TensorFlow、PyTorch、Transformers、Langchain框架。大学英语CET-6。
教育背景
2005 年 9 月-2009 年 7 月 北京信息科技大学 电子信息工程 统招本科
2012 年 9 月-2015 年 3 月 北京信息科技大学 电子与通信工程 统招硕士

